{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0302723c",
   "metadata": {},
   "source": [
    "# Image Classifier Training Pipeline\n",
    "## Data Augmentation, Class Balancing & 2-Layer CNN\n",
    "\n",
    "This notebook demonstrates the complete training pipeline for a fruit image classifier with:\n",
    "- **Data Augmentation**: Rotation, zoom, brightness adjustments, etc.\n",
    "- **Class Balancing**: Handles imbalanced fruit categories\n",
    "- **Simplified Architecture**: Max 2 convolutional layers with Gaussian noise regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4265cf",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb9f943",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\skido\\anaconda3\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input, GaussianNoise\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\skido\\anaconda3\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input, GaussianNoise\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e263d9",
   "metadata": {},
   "source": [
    "## Step 2: Create Data Augmentation Generators\n",
    "\n",
    "The \"Confusion\" Generator creates new variations of your training photos on the fly to help the model learn better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eec077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DATA AUGMENTATION (The \"Confusion\" Generator) ---\n",
    "# This creates new variations of your photos on the fly.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                    # Normalize pixel values\n",
    "    rotation_range=40,                 # Tilt photo up to 40 degrees\n",
    "    width_shift_range=0.2,             # Shift left/right\n",
    "    height_shift_range=0.2,            # Shift up/down\n",
    "    shear_range=0.2,                   # Distort shape (shear)\n",
    "    zoom_range=0.2,                    # Zoom in/out\n",
    "    horizontal_flip=True,              # Mirror image\n",
    "    brightness_range=[0.8, 1.2],       # Simulate different lighting\n",
    "    channel_shift_range=20.0,          # Slight color changes (simulates background tint)\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Test data should NOT be augmented, only scaled.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"‚úì Data augmentation generators created!\")\n",
    "print(\"\\nAugmentation parameters:\")\n",
    "print(\"  - Rotation: ¬±40¬∞\")\n",
    "print(\"  - Shift: ¬±20% (width & height)\")\n",
    "print(\"  - Zoom: ¬±20%\")\n",
    "print(\"  - Brightness: 0.8 - 1.2x\")\n",
    "print(\"  - Horizontal flip: Yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22487996",
   "metadata": {},
   "source": [
    "## Step 3: Load Data Generators\n",
    "\n",
    "Load training and test data from directory structure with augmentation applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'TeamX/data/train',               # Point to your training folder\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,                    # Small batch size for small data\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'TeamX/data/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(f\"‚úì Data generators loaded!\")\n",
    "print(f\"\\nTraining data:\")\n",
    "print(f\"  - Total batches: {len(train_generator)}\")\n",
    "print(f\"  - Classes: {list(train_generator.class_indices.keys())}\")\n",
    "print(f\"  - Class indices: {train_generator.class_indices}\")\n",
    "\n",
    "print(f\"\\nTest data:\")\n",
    "print(f\"  - Total batches: {len(test_generator)}\")\n",
    "print(f\"  - Classes: {list(test_generator.class_indices.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7ccba",
   "metadata": {},
   "source": [
    "## Step 4: Compute Class Weights\n",
    "\n",
    "Handle imbalanced data by computing weights that penalize the model more heavily for mistakes on underrepresented classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e25b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. BALANCING (Handling unequal amounts of data) ---\n",
    "# If 'Apple' has 70 photos and 'Mixed' has 20, this calculates weights\n",
    "# so the model is penalized more for getting 'Mixed' wrong.\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "# Convert to dictionary format required by Keras\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"‚úì Class weights computed!\")\n",
    "print(\"\\nClass Weight Distribution:\")\n",
    "for class_name, class_idx in train_generator.class_indices.items():\n",
    "    weight = class_weight_dict[class_idx]\n",
    "    print(f\"  {class_name}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033607ff",
   "metadata": {},
   "source": [
    "## Step 5: Build Model Architecture\n",
    "\n",
    "Create a simplified CNN with **exactly 2 convolutional layers**, Gaussian noise for regularization, and dropout for preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddab8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. ARCHITECTURE (Add Noise, Remove Complexity) ---\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer + Gaussian Noise (Artificial Static)\n",
    "model.add(Input(shape=(150, 150, 3)))\n",
    "# This adds random noise to training data to prevent memorization\n",
    "model.add(GaussianNoise(0.1))\n",
    "\n",
    "# Convolution Block 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Convolution Block 2 (Max 2 convolutional layers)\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dropout: Randomly sets 50% of inputs to 0.\n",
    "# This forces the model to not rely on specific paths.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))  # 4 classes: Apple, Orange, Banana, Mixed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úì Model created and compiled!\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d21a0a",
   "metadata": {},
   "source": [
    "## Step 6: Setup Training Callbacks\n",
    "\n",
    "Configure callbacks for:\n",
    "- Early stopping (prevent overfitting)\n",
    "- Learning rate reduction (adaptive learning)\n",
    "- Model checkpointing (save best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment directory\n",
    "experiment_dir = Path('experiments/notebook_demo')\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(experiment_dir / 'model_best.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Callbacks configured!\")\n",
    "print(f\"‚úì Experiment directory: {experiment_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402d114",
   "metadata": {},
   "source": [
    "## Step 7: Train the Model\n",
    "\n",
    "**‚è±Ô∏è NOTE:** Training will take several minutes depending on your hardware. The model will train with:\n",
    "- **Data augmentation** applied to training data on-the-fly\n",
    "- **Class weights** to balance imbalanced fruit categories\n",
    "- **Early stopping** to prevent overfitting\n",
    "- **Learning rate reduction** for adaptive optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adcb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. COMPILING AND TRAINING ---\n",
    "print(\"Starting training with Class Weights:\", class_weight_dict)\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"  - Epochs: 50\")\n",
    "print(f\"  - Batch size: 16\")\n",
    "print(f\"  - Learning rate: 0.001\")\n",
    "print(f\"  - Class weights: {class_weight_dict}\")\n",
    "print(f\"  - Data augmentation: Enabled\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    class_weight=class_weight_dict,  # Apply the balancing here\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951b3be",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Training History\n",
    "\n",
    "Plot the training and validation accuracy/loss over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46100a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[0].set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[1].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(experiment_dir / 'training_history.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9fc243",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Model on Test Set\n",
    "\n",
    "Generate predictions and compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af137cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_proba = model.predict(test_generator)\n",
    "y_pred = y_pred_proba.argmax(axis=1)\n",
    "y_test = test_generator.classes\n",
    "\n",
    "# Calculate accuracy\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"‚úì Evaluation completed!\")\n",
    "print(f\"\\nüéØ Final Test Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Get class names\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "class_names_sorted = sorted(class_names, key=lambda x: test_generator.class_indices[x])\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred, target_names=class_names_sorted))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e19d8",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names_sorted,\n",
    "    yticklabels=class_names_sorted,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(experiment_dir / 'confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confusion matrix visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7282547",
   "metadata": {},
   "source": [
    "## Step 11: Save Training History to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_dict = {\n",
    "    'accuracy': history.history['accuracy'],\n",
    "    'val_accuracy': history.history['val_accuracy'],\n",
    "    'loss': history.history['loss'],\n",
    "    'val_loss': history.history['val_loss']\n",
    "}\n",
    "\n",
    "with open(experiment_dir / 'history.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=4)\n",
    "\n",
    "# Save metrics\n",
    "metrics_dict = {\n",
    "    'final_accuracy': float(final_accuracy),\n",
    "    'final_accuracy_percent': float(final_accuracy * 100),\n",
    "    'test_samples': int(len(y_test)),\n",
    "    'class_distribution': {name: int(sum(y_test == test_generator.class_indices[name])) \n",
    "                          for name in class_names_sorted}\n",
    "}\n",
    "\n",
    "with open(experiment_dir / 'metrics.json', 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "print(\"‚úì Training history saved to history.json\")\n",
    "print(\"‚úì Metrics saved to metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f653ba6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **Training Pipeline Completed!**\n",
    "\n",
    "### Key Features Implemented:\n",
    "- ‚úì **Data Augmentation** (rotation, zoom, brightness, shifts)\n",
    "- ‚úì **Class Balancing** (handles imbalanced fruit categories)\n",
    "- ‚úì **Simplified Architecture** (exactly 2 convolutional layers)\n",
    "- ‚úì **Gaussian Noise** (prevents overfitting/memorization)\n",
    "- ‚úì **Dropout Regularization** (50% drop rate)\n",
    "- ‚úì **Early Stopping** (prevents overfitting)\n",
    "- ‚úì **Learning Rate Scheduling** (adaptive optimization)\n",
    "\n",
    "### Output Files:\n",
    "- `model_best.h5` - Best trained model (saved via checkpoint)\n",
    "- `history.json` - Training/validation metrics per epoch\n",
    "- `metrics.json` - Final accuracy and class distribution\n",
    "- `training_history.png` - Accuracy & loss plots\n",
    "- `confusion_matrix.png` - Confusion matrix visualization\n",
    "\n",
    "### Model Architecture:\n",
    "```\n",
    "Input (150√ó150√ó3) ‚Üí Gaussian Noise (0.1)\n",
    "  ‚Üì\n",
    "Conv2D(32, 3√ó3) + ReLU ‚Üí MaxPool(2√ó2)\n",
    "  ‚Üì\n",
    "Conv2D(64, 3√ó3) + ReLU ‚Üí MaxPool(2√ó2)\n",
    "  ‚Üì\n",
    "Flatten ‚Üí Dropout(0.5) ‚Üí Dense(512, ReLU) ‚Üí Dense(4, Softmax)\n",
    "```\n",
    "\n",
    "**Next Steps:** You can now use this trained model for predictions on new fruit images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8907479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update paths since we're running from TeamX/src\n",
    "import os\n",
    "os.chdir('../../')  # Go to root directory for data access"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
